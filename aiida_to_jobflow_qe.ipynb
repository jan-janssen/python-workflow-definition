{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from python_workflow_definition.aiida import write_workflow_json\nfrom python_workflow_definition.jobflow import load_workflow_json\nfrom jobflow.managers.local import run_locally\n\nfrom aiida import load_profile\nload_profile()\n\nworkflow_json_filename =  \"aiida_to_pyiron_base_qe.json\"","metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/srv/conda/envs/notebook/lib/python3.12/site-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n  \"cipher\": algorithms.TripleDES,\n/srv/conda/envs/notebook/lib/python3.12/site-packages/paramiko/transport.py:253: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n  \"class\": algorithms.TripleDES,\n"}],"execution_count":1},{"cell_type":"code","source":"from aiida_workgraph import task, WorkGraph\nfrom typing import Any","metadata":{"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# NOTE: `get_dict` is `get_input_dict`, to compile the input values for the calc tasks\n# NOTE: `add_link` must be from outputs to inputs\nfrom python_workflow_definition.shared import get_dict, get_list","metadata":{"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"@task.pythonjob()\ndef pickle_node(value):\n    \"\"\"Handle data nodes\"\"\"\n    return value","metadata":{"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from quantum_espresso_workflow import generate_structures as _generate_structures\nfrom quantum_espresso_workflow import get_bulk_structure as _get_bulk_structure\nfrom quantum_espresso_workflow import calculate_qe as _calculate_qe\nfrom quantum_espresso_workflow import plot_energy_volume_curve as _plot_energy_volume_curve","metadata":{"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"strain_lst = [0.9, 0.95, 1.0, 1.05, 1.1]","metadata":{"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"get_bulk_structure = task.pythonjob()(_get_bulk_structure)\ngenerate_structures = task.pythonjob()(_generate_structures)\ncalculate_qe = task.pythonjob(outputs=[\"energy\", \"volume\", \"structure\"])(\n    _calculate_qe\n)\nplot_energy_volume_curve = task.pythonjob()(_plot_energy_volume_curve)","metadata":{"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"wg = WorkGraph(\"wg-qe\")","metadata":{"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"pickle_element_task = wg.add_task(\n    pickle_node,\n    name=\"pickle_element\",\n    value=\"Al\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"pickle_a_task = wg.add_task(\n    pickle_node, name=\"pickle_a\", value=4.05\n)","metadata":{"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"pickle_cubic_task = wg.add_task(\n    pickle_node, name=\"pickle_cubic\", value=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"pickle_relax_workdir_task = wg.add_task(\n    pickle_node,\n    name=\"pickle_relax_workdir\",\n    value=\"mini\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ? relax or SCF, or general? -> Should be relax\nrelax_get_dict_task = wg.add_task(\n    task.pythonjob(\n        # outputs=[\"structure\", \"calculation\", \"kpts\", \"pseudopotentials\", \"smearing\"]\n        # outputs=[\"dict\"]\n    )(get_dict),\n    name=\"relax_get_dict\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"pickle_pp_task = wg.add_task(\n    pickle_node,\n    name=\"pseudopotentials\",\n    value={\"Al\": \"Al.pbe-n-kjpaw_psl.1.0.0.UPF\"},\n)","metadata":{"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"pickle_kpts_task = wg.add_task(\n    pickle_node, name=\"kpts_task\", value=[3, 3, 3]  # FIXME: Back to [3, 3, 3]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"pickle_calc_type_relax_task = wg.add_task(\n    pickle_node,\n    name=\"calc_type_relax\",\n    value=\"vc-relax\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"pickle_smearing_task = wg.add_task(\n    pickle_node, name=\"smearing\", value=0.02\n)","metadata":{"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"strain_lst_task = wg.add_task(\n    pickle_node,\n    name=\"pickle_strain_lst\",\n    value=strain_lst,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"get_bulk_structure_task = wg.add_task(\n    get_bulk_structure,\n    name=\"get_bulk_structure\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"relax_task = wg.add_task(\n    calculate_qe,\n    # ! I don't like the `mini` name...\n    name=\"mini\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"generate_structures_task = wg.add_task(\n    generate_structures,\n    name=\"generate_structures\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# here we add the structure outputs based on the number of strains\ndel wg.tasks.generate_structures.outputs[\"result\"]","metadata":{"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"scf_qe_tasks = []\nfor i, strain in enumerate(strain_lst):\n    generate_structures_task.add_output(\"workgraph.any\", f\"s_{i}\")\n\n    scf_qe_task = wg.add_task(\n        calculate_qe,\n        name=f\"qe_{i}\",\n        register_pickle_by_value=True,\n    )\n    scf_qe_tasks.append(scf_qe_task)","metadata":{"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"plot_energy_volume_curve_task = wg.add_task(\n    plot_energy_volume_curve,\n    name=\"plot_energy_volume_curve\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"strain_dir_tasks, scf_get_dict_tasks = [], []\nfor i, strain in enumerate(strain_lst):\n    strain_dir = f\"strain_{i}\"\n\n    strain_dir_task = wg.add_task(\n        pickle_node,\n        name=f\"pickle_{strain_dir}_dir\",\n        value=strain_dir,\n        register_pickle_by_value=True,\n    )\n    strain_dir_tasks.append(strain_dir_task)\n\n    scf_get_dict_task = wg.add_task(\n        task.pythonjob()(get_dict),\n        name=f\"get_dict_{i}\",\n        register_pickle_by_value=True,\n    )\n    scf_get_dict_tasks.append(scf_get_dict_task)\n\n    if i == 0:\n        pickle_calc_type_scf_task = wg.add_task(\n            pickle_node,\n            name=\"calc_type_scf\",\n            value=\"scf\",\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"get_volumes_task = wg.add_task(\n    task.pythonjob()(get_list),\n    name=\"get_volumes\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"get_energies_task = wg.add_task(\n    task.pythonjob()(get_list),\n    name=\"get_energies\",\n    register_pickle_by_value=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Add remaining links\nwg.add_link(\n    pickle_element_task.outputs.result, get_bulk_structure_task.inputs.element\n)\nwg.add_link(pickle_a_task.outputs.result, get_bulk_structure_task.inputs.a)\nwg.add_link(pickle_cubic_task.outputs.result, get_bulk_structure_task.inputs.cubic)","metadata":{"trusted":true},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"NodeLink(from=\"pickle_cubic.result\", to=\"get_bulk_structure.cubic\")"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# `.set` rather than `.add_link`, as get_dict takes `**kwargs` as input\nrelax_get_dict_task.set(\n    {\n        \"structure\": get_bulk_structure_task.outputs.result,\n        \"calculation\": pickle_calc_type_relax_task.outputs.result,\n        \"kpts\": pickle_kpts_task.outputs.result,\n        \"pseudopotentials\": pickle_pp_task.outputs.result,\n        \"smearing\": pickle_smearing_task.outputs.result,\n    }\n)","metadata":{"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"wg.add_link(relax_get_dict_task.outputs.result, relax_task.inputs.input_dict)\nwg.add_link(\n    pickle_relax_workdir_task.outputs.result,\n    relax_task.inputs.working_directory,\n)","metadata":{"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"NodeLink(from=\"pickle_relax_workdir.result\", to=\"mini.working_directory\")"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"wg.add_link(relax_task.outputs.structure, generate_structures_task.inputs.structure)\nwg.add_link(\n    strain_lst_task.outputs.result, generate_structures_task.inputs.strain_lst\n)","metadata":{"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"NodeLink(from=\"pickle_strain_lst.result\", to=\"generate_structures.strain_lst\")"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"for i, (scf_get_dict_task, scf_qe_task, strain_dir_task) in enumerate(\n    list(zip(scf_get_dict_tasks, scf_qe_tasks, strain_dir_tasks))\n):\n    scf_get_dict_task.set(\n        {\n            \"structure\": generate_structures_task.outputs[f\"s_{i}\"],\n            \"calculation\": pickle_calc_type_scf_task.outputs.result,\n            \"kpts\": pickle_kpts_task.outputs.result,\n            \"pseudopotentials\": pickle_pp_task.outputs.result,\n            \"smearing\": pickle_smearing_task.outputs.result,\n        }\n    )\n    wg.add_link(scf_get_dict_task.outputs.result, scf_qe_task.inputs.input_dict)\n    wg.add_link(\n        strain_dir_task.outputs.result, scf_qe_task.inputs.working_directory\n    )\n\n    # collect energy and volume\n    # wg.add_link(scf_qe_task.outputs.energy, get_energies_task.inputs.kwargs)\n    get_energies_task.set({f\"{i}\": scf_qe_task.outputs.energy})\n    # wg.add_link(scf_qe_task.outputs.volume, get_volumes_task.inputs.kwargs)\n    get_volumes_task.set({f\"{i}\": scf_qe_task.outputs.volume})","metadata":{"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"wg.add_link(\n    get_volumes_task.outputs.result,\n    plot_energy_volume_curve_task.inputs.volume_lst,\n)","metadata":{"trusted":true},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"NodeLink(from=\"get_volumes.result\", to=\"plot_energy_volume_curve.volume_lst\")"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"wg.add_link(\n    get_energies_task.outputs.result,\n    plot_energy_volume_curve_task.inputs.energy_lst,\n)","metadata":{"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"NodeLink(from=\"get_energies.result\", to=\"plot_energy_volume_curve.energy_lst\")"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"_ = write_workflow_json(wg=wg, file_name=workflow_json_filename)\n","metadata":{"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"flow = load_workflow_json(file_name=workflow_json_filename)","metadata":{"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"result = run_locally(flow)\nresult","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"2025-03-21 21:07:21,616 INFO Started executing jobs locally\n2025-03-21 21:07:21,739 INFO Starting job - get_bulk_structure (a928f145-84e4-4a9d-abdc-6e0ef091cbe8)\n2025-03-21 21:07:21,742 INFO Finished job - get_bulk_structure (a928f145-84e4-4a9d-abdc-6e0ef091cbe8)\n2025-03-21 21:07:21,743 INFO Starting job - get_dict (a93d6ac7-d39e-4062-8ca9-309ce9abfd73)\n2025-03-21 21:07:21,745 INFO Finished job - get_dict (a93d6ac7-d39e-4062-8ca9-309ce9abfd73)\n2025-03-21 21:07:21,746 INFO Starting job - calculate_qe (7aab8181-1cee-4523-9c87-9c05e61b795d)\n"},{"name":"stderr","output_type":"stream","text":"[jupyter-pyiron-dev-pyth-flow-definition-8esr8q3h:00628] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\nNote: The following floating-point exceptions are signalling: IEEE_INVALID_FLAG\n"},{"name":"stdout","output_type":"stream","text":"2025-03-21 21:08:15,123 INFO Finished job - calculate_qe (7aab8181-1cee-4523-9c87-9c05e61b795d)\n2025-03-21 21:08:15,124 INFO Starting job - generate_structures (4a1f13c0-2ddb-4b73-9839-725d72fd17a3)\n2025-03-21 21:08:15,128 INFO Finished job - generate_structures (4a1f13c0-2ddb-4b73-9839-725d72fd17a3)\n2025-03-21 21:08:15,129 INFO Starting job - get_dict (39d3e03a-a1ad-400b-a581-38777ef58a7c)\n2025-03-21 21:08:15,130 INFO Finished job - get_dict (39d3e03a-a1ad-400b-a581-38777ef58a7c)\n2025-03-21 21:08:15,131 INFO Starting job - get_dict (44553af9-b7e0-45de-aa03-414f812edf49)\n2025-03-21 21:08:15,132 INFO Finished job - get_dict (44553af9-b7e0-45de-aa03-414f812edf49)\n2025-03-21 21:08:15,133 INFO Starting job - get_dict (d608e567-675d-4be8-8e87-88c4f52f8235)\n2025-03-21 21:08:15,134 INFO Finished job - get_dict (d608e567-675d-4be8-8e87-88c4f52f8235)\n2025-03-21 21:08:15,135 INFO Starting job - get_dict (e3a5797e-e3a5-4860-a5dc-1cd567f11ed9)\n2025-03-21 21:08:15,164 INFO Finished job - get_dict (e3a5797e-e3a5-4860-a5dc-1cd567f11ed9)\n2025-03-21 21:08:15,165 INFO Starting job - get_dict (59dda737-685a-43b1-8c60-a8978d513cc6)\n2025-03-21 21:08:15,166 INFO Finished job - get_dict (59dda737-685a-43b1-8c60-a8978d513cc6)\n2025-03-21 21:08:15,167 INFO Starting job - calculate_qe (46b40478-030e-4283-a560-b702ba19598a)\n"},{"name":"stderr","output_type":"stream","text":"[jupyter-pyiron-dev-pyth-flow-definition-8esr8q3h:00651] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"}],"execution_count":null}]}
